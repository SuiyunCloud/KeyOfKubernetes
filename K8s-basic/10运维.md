## 故障排查

1. Pod停留在Pending

   调度器没有介入，通过kubectl describe pod查看实践，通常与资源使用相关

2. Pod停留在waiting

   通常是镜像拉取有问题，看看镜像网路或镜像地址是否正确

3. Pod不断被拉起且看到crashing

   pod完成调度并启动，但启动失败。通常是配置、权限造成，需要查看pod日志

4. Pod处于running但工作不正常

   通常是部分字段拼写错误造成但，校验部署排查，如：kubectl apply --validate -f pod.yaml

5. service无法正常工作

   在排查网络插件问题后，可能是label配置问题，可以查看endpoint的方式检查

## 系统配置

1. Node隔离方式：

   * 编辑node，设置spec.unschedulable: true
   * 执行：kubectl patch node node-1 -p '{"spec":{"unschedulable":true}}'
   * Kubectl cordon node-1

2. label操作

   * 删除：label名字后加-，如：kubeclt label po pod1 role-
   * 修改：kubectl label po pod1 role=master --overwrite

3. 集群环境隔离

   * 通过定义不同namespace隔离资源

   * 定义Context，可以实现集群切换或者命名空间限制访问

     ```yaml
     #不同集群
     apiVersion: v1
     clusters:
     - cluster:
         certificate-authority-data: DATA+OMITTED
         server: https://kubernetes.docker.internal:6443
       name: docker-desktop
     - cluster:
         certificate-authority-data: DATA+OMITTED
         server: https://192.168.31.147:6443
       name: kubernetes
     contexts:
     - context:
         cluster: docker-desktop #约束使用不同的集群
         user: docker-desktop
       name: docker-desktop
     - context:
         cluster: kubernetes
         user: kubernetes-admin
       name: kubernetes-admin@kubernetes
     current-context: docker-desktop
     kind: Config
     preferences: {}
     users:
     - name: docker-desktop
       user:
         client-certificate-data: REDACTED
         client-key-data: REDACTED
     - name: kubernetes-admin
       user:
         client-certificate-data: REDACTED
         client-key-data: REDACTED
     ```

     ```yaml
     #命名空间控制
     apiVersion: v1
     clusters:
     - cluster:
         server: https://kubernetes.docker.internal:6443
       name: docker-desktop
     contexts:
     - context:
         cluster: docker-desktop
         namespace: development  #约束使用命名空间
         user: dev
       name: ctx-dev
     - context:
         cluster: kubernetes
         namespace: production
         user: prod
       name: ctx-prod
     current-context: docker-desktop
     kind: Config
     preferences: {}
     users: null
     ```

     切换context：`kubectl config use-context ctx-dev`

4. 资源限制
   * limit， request背后的机制是将相关参数传递给启动的容器执行器，如docker，由容器执行器实现资源的真正限制
   * limitRange可以进行全局的最大、最小、默认、比例等限制
   * resourcequota：限制租户所能使用资源的总量
   * Pod可以定义spec.priorityClassName: high/medium/low划分不同优先级；通过spec.scopeSelector，resource quota可以对不同优先级进行定义
   
5. Pod内共享进程命名空间

   使用场景是：一个debug容器，对业务容器内的进程进行差错

   特性：各个容器的进程ID混合在一个环境中，pause容器拥有1号进程，对必须用1号进程启动的程序如systemd则无法使用；一个容器的文件系统存在于/proc/$pid/root下，不同容器可以相互访问

6. PID资源管理

   可以设置pod和node两个级别的PID的限制，在kubelete启动时进行相关设置，如分别开启特性--feature-gates=SupportPodPidsLimit=true和--feature-gates=SupportNodePidsLimit=true

7. CPU亲和度

   使用场景：当节点上是cpu密集型pod，希望尽量将任务调度到同一个cpu上

   方法：kubelete启动参数--cpu-manager-policy=static

   原理：在上述启动参数设置为static后，对QoS为Guaranteed的pod，当其cpu request为1的整数时，允许容器独占一个或多个cpu核，从而减少上下文切换次数。

8. 拓扑管理器
   对硬件配合要求较高对场景，拓扑管理器帮助提供多种资源需求组合，如从相同NUMA节点分配cpu、内存。需要与QoS搭配使用

9. Pod驱逐
   * nodefs是kubelet用于存储卷系统、服务程序日志等的文件系统；imagefs是容器运行时使用的可选文件系统，用于保存容器镜像和容器可写层数据
   * 默认情况下，驱逐条件
     * nodefs.available < 10%
     * nodefs.inodesFree < 5%
     * imagefs.available < 15%
   * kubelete驱逐的方式有两种
     * 驱逐软阈值：当达到驱逐到阈值后，等待一个管理员设置的宽限期后，再执行驱逐；--eviction-soft和--eviction-soft-grace-period定义
     * 驱逐硬阈值：到达条件直接驱逐；--eviction-hard定义
   * Kubernetes1.9后，kubelet只根据Pod的nodefs使用量排序，并选择使用量最多的Pod进行驱逐，即使QoS为Guaranteed的Pod也可能被驱逐
   * 当节点为MemoryPressure时，不再调度新的BestEffort Pod；当节点为DiskPressure时，不再向节点调度Pod