

Readiness指针判断服务是否就绪，只有就绪流量才会接入

liveness指针判断服务是否正常，不健康则杀Pod



探测方式：

* httpGet：返回200-399则认为健康
* Exec：执行命令，命令返回值为0则认为健康。最好用编译的程序来判断，性能会比shell命令提高30%
* tcpSocket：通过IP和port的tcp能够正常建立，则认为健康

常用配置：

* initialDelaySeconds：启动后延迟检查
* periodSeconds：探测周期
* timeoutSecond：探测超时

## 故障排查

1. Pod停留在Pending

   调度器没有介入，通过kubectl describe pod查看实践，通常与资源使用相关

2. Pod停留在waiting

   通常是镜像拉取有问题，看看镜像网路或镜像地址是否正确

3. Pod不断被拉起且看到crashing

   pod完成调度并启动，但启动失败。通常是配置、权限造成，需要查看pod日志

4. Pod处于running但工作不正常

   通常是部分字段拼写错误造成但，校验部署排查，如：kubectl apply --validate -f pod.yaml

5. service无法正常工作

   在排查网络插件问题后，可能是label配置问题，可以查看endpoint的方式检查

## 远程调试

* 自动补全

  ```shell
  yum install -y bash-completion 
  source /usr/share/bash-completion/bash_completion
  source <(kubectl completion bash)
  echo "source <(kubectl completion bash)" >> ~/.bashrc
  
  ```

* 当集群中应用依赖的应用需要本地调试时：

  使用Telepresence将本地应用代理到集群中的一个service上

  `Telepresence --swap-deployment $DEPLOYMENT_NAME`

* 当本地开发的应用需要调用集群中的服务时：

  使用port- forward将远程应用代理到本地端口上

  `kubectl port-forward svc/app -n app-namespace`

* 进入pod中调试

  通过kubectl 的一个插件kubectl-debug，能够用工具pod连接目标pod，从而对其进行诊断。

  `kubectl debug 目标pod名`

## 监控

k8s监控有三种接口：

* Resource Metrics

  对应的接口是 metrics.k8s.io，主要的实现就是 metrics-server，它提供的是资源的监控，比较常见的是节点级别、pod 级别、namespace 级别、class 级别。这类的监控指标都可以通过 metrics.k8s.io 这个接口获取到。

* Custom Metrics

  对应的 API 是 custom.metrics.k8s.io，主要的实现是 Prometheus。它提供的是资源监控和自定义监控，资源监控和上面的资源监控其实是有覆盖关系的，而这个自定义监控指的是：比如应用上面想暴露一个类似像在线人数，或者说调用后面的这个数据库的 MySQL 的慢查询。这些其实都是可以在应用层做自己的定义的，然后并通过标准的 Prometheus 的 client，暴露出相应的 metrics，然后再被 Prometheus 进行采集。

* External Metrics

  external.metrics.k8s.io。主要的实现厂商就是各个云厂商的 provider，通过这个 provider 可以获取云资源的监控指标。

## 日志

fluentd以sidecar模式收集日志存储到elasticsearch，再在Kibana中展示

![fluentd daemonset 2](/Users/cloud/Knowledge/22CloudNative/K8s learning/pics/fluentd-daemonset-2.png)